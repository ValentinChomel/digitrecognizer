{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognizer\n",
    "Valentin Chomel\n",
    "30/01/2019\n",
    "\n",
    "### Introduction \n",
    "Il s’agit d’un réseau de neurones à convolution séquentielle à 5 couches pour la reconnaissance des chiffres, formé sur le dataset MNIST. Il est construit avec l'API keras (backend Tensorflow). Tout d'abord, je vais préparer les données (images manuscrites à chiffres), puis je me concentrerai sur la modélisation et l'évaluation CNN.\n",
    "\n",
    "For computational reasons, i set the number of steps (epochs) to 2, if you want to achieve 99+% of accuracy set it to 30.\n",
    "\n",
    "Ce notebook se décompose en 3 parties :\n",
    "\n",
    "1 - La préparation des données\n",
    "2 - La modélisation et l'évaluation du CNN\n",
    "3 - Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation des données\n",
    "#### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "test = pd.read_csv(\"./input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEFCAYAAAD5bXAgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train[\"label\"]\n",
    "\n",
    "# Supprimer la colonne 'label'\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "\n",
    "# Liberation d'espace\n",
    "#del train \n",
    "\n",
    "# Affichage du nombre d'observations dans chaque catégorie à l'aide de barres.\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note que les comptes sont similaires pour les 10 chiffres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérifier les valeurs nulles et manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification des données\n",
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a pas de valeurs manquantes dans les datasets train et test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalisation en niveaux de gris pour réduire l'effet des différences d'éclairage.\n",
    "\n",
    "De plus, le CNN converge plus rapidement sur les données [0..1] que sur [0..255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not operate 255.0 with block values ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, raise_on_error, try_cast, mgr)\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(other)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             result = expressions.evaluate(op, str_rep, x, y,\n\u001b[0;32m-> 1176\u001b[0;31m                                           raise_on_error=True, **eval_kwargs)\n\u001b[0m\u001b[1;32m   1177\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, op_str, a, b, raise_on_error, use_numexpr, **eval_kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m         return _evaluate(op, op_str, a, b, raise_on_error=raise_on_error,\n\u001b[0;32m--> 211\u001b[0;31m                          **eval_kwargs)\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_numexpr\u001b[0;34m(op, op_str, a, b, raise_on_error, truediv, reversed, **eval_kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m                                  \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'safe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruediv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruediv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                  **eval_kwargs)\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/numexpr/necompiler.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(ex, local_dict, global_dict, out, order, casting, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mevaluate_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-8b27153423ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Normalize the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_combine_const\u001b[0;34m(self, other, func, raise_on_error)\u001b[0m\n\u001b[1;32m   3541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_combine_const\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m         new_data = self._data.eval(func=func, other=other,\n\u001b[0;32m-> 3543\u001b[0;31m                                    raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m   3544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, func, other, raise_on_error, try_cast, mgr)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;31m# technically a broadcast error in numpy can 'work' by returning a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/val/D1/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mhandle_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1172\u001b[0m                 \u001b[0;31m# The 'detail' variable is defined in outer scope.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 raise TypeError('Could not operate %s with block values %s' %\n\u001b[0;32m-> 1174\u001b[0;31m                                 (repr(other), str(detail)))  # noqa\n\u001b[0m\u001b[1;32m   1175\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;31m# return the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not operate 255.0 with block values "
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remodeler l’image en 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images de train et test (28px x 28px) ont été stocké dans pandas.Dataframe sous forme de vecteurs 1D de 784 valeurs. Nous remodelons toutes les données en matrices 3D 28x28x1.\n",
    "\n",
    "Keras nécessite une dimension supplémentaire à la fin qui correspond aux canaux. Les images MNIST ont une échelle de gris et n'utilisent qu'un seul canal. \n",
    "Note : Pour les images RVB, il y a 3 canaux, nous aurions remodelé les vecteurs 784px en matrices 3D 28x28x3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codage de label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encodage one-hot des labels (ex: 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les étiquettes sont des nombres à 10 chiffres de 0 à 9. Nous devons coder ces étiquettes en one-hot (ex: 2 -> [0,0,1,0,0,0,0,0,0,0])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entraiment divisé et validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Définition du random seed\n",
    "random_seed = 2\n",
    "\n",
    "# Séparer le train set et le jeu de validation pour l'ajustement\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cinde le train set en deux parties: une petite fraction (10%) est devenue le jeu de validation pour lequel le modèle est évalué et le reste (90%) est utilisé pour former le modèle.\n",
    "\n",
    "Comme nous disposons de 42 000 images d'apprentissage étiquettées (voir dessus), une scission aléatoire du train ne provoque pas la surreprésentation de certaines étiquettes dans l'ensemble de validation. \n",
    "\n",
    "Attention : avec certains ensembles de données non équilibrés, une simple division aléatoire pourrait entraîner une évaluation inexacte lors de la validation.\n",
    "Pour éviter cela, utiliser l’option stratify = True dans la fonction train_test_split (uniquement pour les versions> = 0.17 de Sklearn)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple (image et étiquette) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un exemple\n",
    "g = plt.imshow(X_train[0][:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API séquentielle Keras, où il suffit d'ajouter une couche à la fois, à partir de l'entrée.\n",
    "\n",
    "Le premier est la couche convolutionnelle (Conv2D). C'est comme un ensemble de filtres pouvant être appris. J'ai choisi de définir 32 filtres pour les deux premières couches de conv2D et 64 filtres pour les deux derniers. Chaque filtre transforme une partie de l'image (définie par la taille du noyau) à l'aide du filtre de noyau. La matrice de filtrage du noyau est appliquée à l’ensemble de l’image. Les filtres peuvent être vus comme une transformation de l'image.\n",
    "\n",
    "Le CNN peut isoler les caractéristiques utiles partout de ces images transformées (cartes de caractéristiques).\n",
    "\n",
    "La deuxième couche importante de CNN est la couche de mise en commun (MaxPool2D). Cette couche sert simplement de filtre de sous-échantillonnage. Il regarde les 2 pixels voisins et choisit la valeur maximale. Celles-ci sont utilisées pour réduire les coûts de calcul et, dans une certaine mesure, réduire également le surajustement. Nous devons choisir la taille de la mise en commun (c'est-à-dire la taille de la zone mise en commun à chaque fois), plus la dimension de mise en commun est élevée, plus le sous-échantillonnage est important.\n",
    "\n",
    "Combinant des couches de convolution et de regroupement, CNN peut combiner des fonctionnalités locales et apprendre des fonctionnalités plus globales de l'image.\n",
    "\n",
    "L'abandon est une méthode de régularisation dans laquelle une proportion de noeuds de la couche est ignorée de manière aléatoire (en définissant leur poids à zéro) pour chaque échantillon d'apprentissage. Cela laisse tomber au hasard une proposition du réseau et oblige le réseau à apprendre les fonctionnalités de manière distribuée. Cette technique améliore également la généralisation et réduit le surajustement.\n",
    "\n",
    "'relu' est le redresseur (fonction d'activation max (0, x). La fonction d'activation du redresseur permet d'ajouter une non-linéarité au réseau.\n",
    "\n",
    "La couche Flatten est utilisée pour convertir les cartes de caractéristiques finales en un seul vecteur 1D. Cette étape d'aplatissement est nécessaire pour que utiliser des couches entièrement connectées après certaines couches convolutionnelles / maxpool. Il combine toutes les caractéristiques locales trouvées des couches convolutionnelles précédentes.\n",
    "\n",
    "En fin de compte, j’ai utilisé les caractéristiques de deux couches (Dense) entièrement connectées, c’est-à-dire un classifieur artificiel de réseaux neuronaux (ANN). Dans la dernière couche (Dense (10, activation = \"softmax\")), la distribution de sortie nette de la probabilité de chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the CNN model \n",
    "# my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définir l'optimiseur et l'annealer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois nos couches ajoutées au modèle, nous devons définir une fonction de score, une fonction de perte et un algorithme d'optimisation.\n",
    "\n",
    "Nous définissons la fonction de perte pour mesurer la performance médiocre de notre modèle sur des images avec des étiquettes connues. C'est le taux d'erreur entre les étiquettes observées et celles prédites. Nous utilisons un formulaire spécifique pour les classifications catégoriques (> 2 classes) appelé \"categorical_crossentropy\".\n",
    "\n",
    "La fonction la plus importante est l'optimiseur. Cette fonction améliorera de manière itérative les paramètres (filtres les valeurs du noyau, les poids et le biais des neurones ...) afin de minimiser la perte.\n",
    "\n",
    "J'ai choisi RMSprop (avec les valeurs par défaut), c'est un optimiseur très efficace. La mise à jour RMSProp ajuste la méthode Adagrad de manière très simple afin de réduire son taux d’apprentissage agressif et décroissant de façon monotone. Nous aurions aussi pu utiliser l'optimiseur de descente de gradient stochastique ('sgd'), mais il est plus lent que RMSprop.\n",
    "\n",
    "La fonction métrique \"precision\" est utilisée pour évaluer les performances de notre modèle. Cette fonction métrique est similaire à la fonction de perte, sauf que les résultats de l'évaluation métrique ne sont pas utilisés lors de la formation du modèle (uniquement pour l'évaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Définition de l'optimiseur\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compilation du modele\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de faire converger l'optimiseur plus rapidement et au plus près du minimum global de la fonction de perte, j'ai utilisé une méthode de recuit du taux d'apprentissage (LR).\n",
    "\n",
    "Le LR est l’étape par laquelle l’optimiseur parcourt le «paysage des pertes». Plus le LR est élevé, plus les marches sont grandes et plus la convergence est rapide. Cependant, l'échantillonnage est très faible avec un LR élevé et l'optimiseur pourrait probablement tomber dans un minimum local.\n",
    "\n",
    "Il est préférable d’avoir un taux d’apprentissage décroissant pendant la formation pour atteindre efficacement le minimum global de la fonction de perte.\n",
    "\n",
    "Pour conserver l'avantage du temps de calcul rapide avec un LR élevé, on diminue le LR de manière dynamique toutes les X étapes (époque) en fonction de son utilité (lorsque la précision n'est pas améliorée).\n",
    "\n",
    "Avec la fonction ReduceLROnPlateau de Keras.callbacks, je choisis de réduire de moitié le LR si la précision n’est pas améliorée au bout de 3 époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'éviter tout problème de surajustement, nous devons développer artificiellement notre ensemble de données numériques manuscrites. Nous pouvons rendre votre jeu de données existant encore plus grand. L'idée est de modifier les données d'apprentissage avec de petites transformations pour reproduire les variations qui se produisent lorsque quelqu'un écrit un chiffre.\n",
    "\n",
    "Par exemple, le nombre n'est pas centré L'échelle n'est pas la même (certains écrivent avec de grands / petits nombres) L'image est pivotée ...\n",
    "\n",
    "Les approches qui modifient les données d'apprentissage de manière à modifier la représentation du tableau tout en conservant le même libellé sont appelées techniques d'augmentation de données. Certaines augmentations populaires utilisées par les utilisateurs sont les niveaux de gris, les inversions horizontales, les inversions verticales, les cultures aléatoires, les tremblements de couleur, les translations, les rotations et bien plus encore.\n",
    "\n",
    "En appliquant seulement quelques-unes de ces transformations à nos données de formation, nous pouvons facilement doubler ou tripler le nombre d'exemples de formation et créer un modèle très robuste.\n",
    "\n",
    "L'amélioration est importante:\n",
    "\n",
    "Sans augmentation des données, j'ai obtenu une précision de 98,114%\n",
    "Avec l'augmentation des données, j'ai atteint 99,67% de précision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sans augmentation des données, j'ai obtenu une précision de 0,98114\n",
    "#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "#          validation_data = (X_val, Y_val), verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Avec augmentation des données pour éviter les surajustements (précision 0,99286)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'augmentation des données, j'ai choisi de:\n",
    "\n",
    "Faire pivoter au hasard des images d'entraînement de 10 degrés\n",
    "Zoomer au hasard de 10% sur certaines images d'entraînement\n",
    "Décalage aléatoire des images horizontalement de 10% de la largeur\n",
    "Décalage aléatoire des images verticalement de 10% de la hauteur\n",
    "Je n'ai pas appliqué vertical_flip ni horizontal_flip, car cela aurait pu entraîner une classification erronée des nombres symétriques tels que 6 et 9.\n",
    "\n",
    "Une fois que notre modèle est prêt, nous ajustons le jeu de données de formation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Courbes de formation et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle atteint une précision de près de 99% (98,7 +%) sur l'ensemble de données de validation après 2 époques. La précision de la validation est supérieure à la précision de la formation presque toutes les heures pendant la formation. Cela signifie que notre modèle ne suraliment pas le kit d’entraînement.\n",
    "\n",
    "Notre modèle est bien formé !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion peut être très utile pour voir les inconvénients de votre modèle.\n",
    "Je trace la matrice de confusion des résultats de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrix \n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the validation dataset\n",
    "Y_pred = model.predict(X_val)\n",
    "# Convert predictions classes to one hot vectors \n",
    "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(Y_val,axis = 1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir ici que notre CNN fonctionne très bien sur tous les chiffres avec peu d’erreurs compte tenu de la taille de l’ensemble de validation (4 200 images).\n",
    "\n",
    "Cependant, il semble que notre CNN ait quelques problèmes avec les chiffres 4, mais ils sont mal classés en 9. Il est parfois très difficile de saisir la différence entre 4 et 9 lorsque les courbes sont lisses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons les erreurs.\n",
    "\n",
    "Je veux voir les erreurs les plus importantes. Pour cela, je dois connaître la différence entre les probabilités de valeur réelle et celles prédites dans les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some error results \n",
    "\n",
    "# Errors are difference between predicted labels and true labels\n",
    "errors = (Y_pred_classes - Y_true != 0)\n",
    "\n",
    "Y_pred_classes_errors = Y_pred_classes[errors]\n",
    "Y_pred_errors = Y_pred[errors]\n",
    "Y_true_errors = Y_true[errors]\n",
    "X_val_errors = X_val[errors]\n",
    "\n",
    "def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n",
    "    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n",
    "    n = 0\n",
    "    nrows = 2\n",
    "    ncols = 3\n",
    "    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "    for row in range(nrows):\n",
    "        for col in range(ncols):\n",
    "            error = errors_index[n]\n",
    "            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n",
    "            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n",
    "            n += 1\n",
    "\n",
    "# Probabilities of the wrong predicted numbers\n",
    "Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n",
    "\n",
    "# Predicted probabilities of the true values in the error set\n",
    "true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n",
    "\n",
    "# Difference between the probability of the predicted label and the true label\n",
    "delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n",
    "\n",
    "# Sorted list of the delta prob errors\n",
    "sorted_dela_errors = np.argsort(delta_pred_true_errors)\n",
    "\n",
    "# Top 6 errors \n",
    "most_important_errors = sorted_dela_errors[-6:]\n",
    "\n",
    "# Show the top 6 errors\n",
    "display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les erreurs les plus importantes sont aussi les plus intrigantes.\n",
    "\n",
    "Pour ces six cas, le modèle n'est pas ridicule. Certaines de ces erreurs peuvent aussi être commises par des humains, en particulier pour un 9 très proche d'un 4. Les 9 derniers sont également très trompeurs, il me semble que c'est un 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(test)\n",
    "\n",
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
